{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "import logging \n",
    "# Load the environment variables from .env file\n",
    "load_dotenv('/home/wjones/CC/Capstone/tbd2/Track/.env', override=True)\n",
    "logging.basicConfig(filename='db_insert.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# Get the database credentials from environment variables\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASS')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "\n",
    "# Connect to the database\n",
    "db_params = {\n",
    "    'dbname': db_name,\n",
    "    'user': db_user,\n",
    "    'password' : db_password,\n",
    "    'host' : db_host,\n",
    "    'port' : db_port\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_params):\n",
    "    \"\"\"Connect to the PostgreSQL database server.\"\"\"\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_728109/3412325704.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/races.csv')\n",
    "\n",
    "# extracts the second string of numbers from the URL\n",
    "def extract_id(url):\n",
    "    meet_id = url.split('/')[-3] if url else None\n",
    "    return meet_id\n",
    "\n",
    "# Apply the function to the 'event_url' column and replace 'tffrs_meet_id'\n",
    "df['tffrs_meet_id'] = df['event_url'].apply(extract_id)\n",
    "\n",
    "# Write the  back to the CSV file\n",
    "df.to_csv('csv/merged_with_section_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load updated_race_urls.csv into a dictionary\n",
    "with open('csv/updated_race_urls.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    dict_one = {row['meet_url']: row for row in reader}\n",
    "\n",
    "# Load merged_with_section_id.csv into a list\n",
    "with open('csv/merged_with_section_id.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    list_two = list(reader)\n",
    "\n",
    "# Merge the data\n",
    "merged_data = []\n",
    "for url, row_one in dict_one.items():\n",
    "    matching_rows = [row for row in list_two if row['meet_url'] == url]\n",
    "    for row_two in matching_rows:\n",
    "        merged_row = {**row_one, **row_two}\n",
    "        merged_data.append(merged_row)\n",
    "\n",
    "# Write the merged data to a new CSV file\n",
    "with open('csv/merged_data.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=merged_data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is to add sex to the races based on the url\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open('csv/merged_data.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "# Add the 'sex' field\n",
    "for row in data:\n",
    "    if 'Men' in row['event_url']:\n",
    "        row['sex'] = 'M'\n",
    "    elif 'Women' in row['event_url']:\n",
    "        row['sex'] = 'F'\n",
    "    else:\n",
    "        row['sex'] = ''\n",
    "\n",
    "# Write the updated data back to the CSV file\n",
    "with open('csv/final_race.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['meet_url','event_name','event_url','tffrs_meet_id','meet_name','date','location', 'sex']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import re\n",
    "\n",
    "# BUG this does not work properly and gives dates back wrong\n",
    "def find_date_in_string(input_string):\n",
    "\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip()\n",
    "    \n",
    "    # if there is a date range in the string\n",
    "    match = re.match(r'(\\w+ \\d+)-(\\w+ \\d+), (\\d{4})', input_string)\n",
    "\n",
    "    if match:\n",
    "\n",
    "        start_date_str = f'{match.group(1)}, {match.group(3)}'\n",
    "        end_date_str = f'{match.group(2)}, {match.group(3)}'\n",
    "\n",
    "        # Parse the start date\n",
    "        start_dates = list(datefinder.find_dates(start_date_str))\n",
    "        if start_dates:\n",
    "            return start_dates[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No start date found in string: {input_string}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Handle non-range dates like DNS or DNF\n",
    "        matches = list(datefinder.find_dates(input_string))\n",
    "        if matches:\n",
    "            return matches[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No date found in string: {input_string}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meet_url,event_name,event_url,tffrs_meet_id,meet_name,date,location,sex\n",
    "def insert_race(conn, race: Dict):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO Races (meet_name, section, tfrrs_url, date, sex, location, tfrrs_meet_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (tfrrs_meet_id) DO UPDATE SET\n",
    "                meet_name = EXCLUDED.meet_name,\n",
    "                section = EXCLUDED.section,\n",
    "                tfrrs_url = EXCLUDED.tfrrs_url,\n",
    "                date = EXCLUDED.date,\n",
    "                sex = EXCLUDED.sex,\n",
    "                location = EXCLUDED.location,\n",
    "                tfrrs_meet_id = EXCLUDED.tfrrs_meet_id;\n",
    "        \"\"\", (race['meet_name'], race['event_name'], race['event_url'], race['date'], race['sex'], race['location'], race['tffrs_meet_id']))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def main():\n",
    "    conn = connect_db(db_params)\n",
    "\n",
    "    with open('csv/final_race.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data = list(reader)\n",
    "\n",
    "    for race in data:\n",
    "        #race['date'] = find_date_in_string(race['date'])\n",
    "        #print(race)\n",
    "        insert_race(conn, race)\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
