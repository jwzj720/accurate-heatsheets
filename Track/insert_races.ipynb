{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "import logging \n",
    "# Load the environment variables from .env file\n",
    "load_dotenv('/home/wjones/CC/Capstone/tbd2/LACCTiC/.env', override=True)\n",
    "logging.basicConfig(filename='db_insert.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# Get the database credentials from environment variables\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASS')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "\n",
    "# Connect to the database\n",
    "db_params = {\n",
    "    'dbname': db_name,\n",
    "    'user': db_user,\n",
    "    'password' : db_password,\n",
    "    'host' : db_host,\n",
    "    'port' : db_port\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_params):\n",
    "    \"\"\"Connect to the PostgreSQL database server.\"\"\"\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CSV/merged.csv')\n",
    "\n",
    "# extracts the second string of numbers from the URL\n",
    "def extract_id(url):\n",
    "    meet_id = url.split('/')[-3] if url else None\n",
    "    return meet_id\n",
    "\n",
    "# Apply the function to the 'event_url' column and replace 'tffrs_meet_id'\n",
    "df['tffrs_meet_id'] = df['event_url'].apply(extract_id)\n",
    "\n",
    "# Write the  back to the CSV file\n",
    "df.to_csv('merged_with_section_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to merge the two files into one file to then insert sections into the DB\n",
    "\n",
    "import csv\n",
    "\n",
    "# Read the first CSV file into a list of dictionaries\n",
    "with open('CSV/one.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file, fieldnames=['meet_url', 'event', 'event_url'])\n",
    "    list_one = list(reader)\n",
    "\n",
    "# Read the second CSV file into a dictionary\n",
    "with open('CSV/two.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file, fieldnames=['meet_name', 'meet_url', 'meet_id', 'date', 'location'])\n",
    "    dict_two = {row['meet_url']: row for row in reader}\n",
    "\n",
    "# Merge the data\n",
    "merged_data = []\n",
    "for row in list_one:\n",
    "    if row['meet_url'] in dict_two:\n",
    "        merged_row = {**row, **dict_two[row['meet_url']]}\n",
    "        merged_data.append(merged_row)\n",
    "\n",
    "# write the merged files into a new file\n",
    "with open('merged.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['meet_url', 'event', 'event_url', 'meet_name', 'meet_id', 'date', 'location']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is to add sex to the races based on the url\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open('merged.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "# Add the 'sex' field\n",
    "for row in data:\n",
    "    if 'Men' in row['event_url']:\n",
    "        row['sex'] = 'M'\n",
    "    elif 'Women' in row['event_url']:\n",
    "        row['sex'] = 'F'\n",
    "    else:\n",
    "        row['sex'] = ''\n",
    "\n",
    "# Write the updated data back to the CSV file\n",
    "with open('merged.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['meet_url', 'event', 'event_url', 'meet_name', 'meet_id', 'date', 'location', 'sex']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import re\n",
    "\n",
    "# BUG this does not work properly and gives dates back wrong\n",
    "def find_date_in_string(input_string):\n",
    "\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip()\n",
    "    \n",
    "    # if there is a date range in the string\n",
    "    match = re.match(r'(\\w+ \\d+)-(\\w+ \\d+), (\\d{4})', input_string)\n",
    "\n",
    "    if match:\n",
    "\n",
    "        start_date_str = f'{match.group(1)}, {match.group(3)}'\n",
    "        end_date_str = f'{match.group(2)}, {match.group(3)}'\n",
    "\n",
    "        # Parse the start date\n",
    "        start_dates = list(datefinder.find_dates(start_date_str))\n",
    "        if start_dates:\n",
    "            return start_dates[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No start date found in string: {input_string}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Handle non-range dates like DNS or DNF\n",
    "        matches = list(datefinder.find_dates(input_string))\n",
    "        if matches:\n",
    "            return matches[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No date found in string: {input_string}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_race(conn, race: Dict):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO Races (meet_id, meet_name, section, tfrrs_url, date, sex, location, tffrs_meet_id)\n",
    "            VALUES (nextval('meet_id_seq'), %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (tffrs_meet_id) DO UPDATE SET\n",
    "                meet_name = EXCLUDED.meet_name,\n",
    "                section = EXCLUDED.section,\n",
    "                tfrrs_url = EXCLUDED.tfrrs_url,\n",
    "                date = EXCLUDED.date,\n",
    "                sex = EXCLUDED.sex,\n",
    "                location = EXCLUDED.location,\n",
    "                tffrs_meet_id = EXCLUDED.tffrs_meet_id;\n",
    "        \"\"\", (race['meet_name'], race['event'], race['event_url'], race['date'], race['sex'], race['location'], race['tffrs_meet_id']))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    conn = connect_db(db_params)\n",
    "\n",
    "    # Read the merged CSV file into a list of dictionaries\n",
    "    with open('CSV/merged1.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data = list(reader)\n",
    "\n",
    "    for race in data:\n",
    "        # Convert the 'date' field to a datetime object\n",
    "        race['date'] = find_date_in_string(race['date'])\n",
    "        #print(race)\n",
    "        insert_race(conn, race)\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_kernal",
   "language": "python",
   "name": "capstone_kernal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
