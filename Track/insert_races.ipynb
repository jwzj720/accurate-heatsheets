{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "import logging \n",
    "# Load the environment variables from .env file\n",
    "load_dotenv('/home/wjones/CC/Capstone/tbd2/Track/.env', override=True)\n",
    "logging.basicConfig(filename='db_insert.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# Get the database credentials from environment variables\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASS')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "\n",
    "# Connect to the database\n",
    "db_params = {\n",
    "    'dbname': db_name,\n",
    "    'user': db_user,\n",
    "    'password' : db_password,\n",
    "    'host' : db_host,\n",
    "    'port' : db_port\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_params):\n",
    "    \"\"\"Connect to the PostgreSQL database server.\"\"\"\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_728109/3412325704.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('csv/races.csv')\n",
    "\n",
    "# extracts the second string of numbers from the URL\n",
    "def extract_id(url):\n",
    "    meet_id = url.split('/')[-3] if url else None\n",
    "    return meet_id\n",
    "\n",
    "# Apply the function to the 'event_url' column and replace 'tffrs_meet_id'\n",
    "df['tffrs_meet_id'] = df['event_url'].apply(extract_id)\n",
    "\n",
    "# Write the  back to the CSV file\n",
    "df.to_csv('csv/merged_with_section_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to merge the two files into one file to then insert sections into the DB\n",
    "\n",
    "import csv\n",
    "\n",
    "# Read the first CSV file into a list of dictionaries\n",
    "with open('csv/updated_race_urls.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file, fieldnames=['meet_name','meet_url','date','location'])\n",
    "    list_one = list(reader)\n",
    "\n",
    "# Read the second CSV file into a dictionary\n",
    "with open('csv/merged_with_section_id.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file, fieldnames=['meet_url','event_name','event_url','meet_name','tffrs_meet_id'])\n",
    "    dict_two = {row['meet_url']: row for row in reader}\n",
    "\n",
    "# Merge the data\n",
    "merged_data = []\n",
    "for row in list_one:\n",
    "    if row['meet_url'] in dict_two:\n",
    "        merged_row = {**row, **dict_two[row['meet_url']]}\n",
    "        merged_data.append(merged_row)\n",
    "\n",
    "# write the merged files into a new file\n",
    "with open('csv/final_race.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['meet_url','event_name','event_url','tffrs_meet_id', 'meet_name','date','location']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is to add sex to the races based on the url\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open('csv/final_race.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    data = list(reader)\n",
    "\n",
    "# Add the 'sex' field\n",
    "for row in data:\n",
    "    if 'Men' in row['event_url']:\n",
    "        row['sex'] = 'M'\n",
    "    elif 'Women' in row['event_url']:\n",
    "        row['sex'] = 'F'\n",
    "    else:\n",
    "        row['sex'] = ''\n",
    "\n",
    "# Write the updated data back to the CSV file\n",
    "with open('csv/final_race.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['meet_url','event_name','event_url','tffrs_meet_id','meet_name','date','location', 'sex']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import re\n",
    "\n",
    "# BUG this does not work properly and gives dates back wrong\n",
    "def find_date_in_string(input_string):\n",
    "\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip()\n",
    "    \n",
    "    # if there is a date range in the string\n",
    "    match = re.match(r'(\\w+ \\d+)-(\\w+ \\d+), (\\d{4})', input_string)\n",
    "\n",
    "    if match:\n",
    "\n",
    "        start_date_str = f'{match.group(1)}, {match.group(3)}'\n",
    "        end_date_str = f'{match.group(2)}, {match.group(3)}'\n",
    "\n",
    "        # Parse the start date\n",
    "        start_dates = list(datefinder.find_dates(start_date_str))\n",
    "        if start_dates:\n",
    "            return start_dates[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No start date found in string: {input_string}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Handle non-range dates like DNS or DNF\n",
    "        matches = list(datefinder.find_dates(input_string))\n",
    "        if matches:\n",
    "            return matches[0].strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            print(f\"No date found in string: {input_string}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_race(conn, race: Dict):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO Races (meet_name, section, tfrrs_url, date, sex, location, tffrs_meet_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (tffrs_meet_id) DO UPDATE SET\n",
    "                meet_name = EXCLUDED.meet_name,\n",
    "                section = EXCLUDED.section,\n",
    "                tfrrs_url = EXCLUDED.tfrrs_url,\n",
    "                date = EXCLUDED.date,\n",
    "                sex = EXCLUDED.sex,\n",
    "                location = EXCLUDED.location,\n",
    "                tffrs_meet_id = EXCLUDED.tffrs_meet_id;\n",
    "        \"\"\", (race['meet_name'], race['event'], race['event_url'], race['date'], race['sex'], race['location'], race['tffrs_meet_id']))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def main():\n",
    "    conn = connect_db(db_params)\n",
    "\n",
    "    with open('csv/final_race.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data = list(reader)\n",
    "\n",
    "    for race in data:\n",
    "        #race['date'] = find_date_in_string(race['date'])\n",
    "        #print(race)\n",
    "        insert_race(conn, race)\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'event'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(reader)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m race \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Convert the 'date' field to a datetime object\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#race['date'] = find_date_in_string(race['date'])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(race)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[43minsert_race\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36minsert_race\u001b[0;34m(conn, race)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_race\u001b[39m(conn, race: Dict):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m      3\u001b[0m         cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m            INSERT INTO Races (meet_name, section, tfrrs_url, date, sex, location, tffrs_meet_id)\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m            VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m            ON CONFLICT (tffrs_meet_id) DO UPDATE SET\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m                meet_name = EXCLUDED.meet_name,\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m                section = EXCLUDED.section,\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                tfrrs_url = EXCLUDED.tfrrs_url,\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m                date = EXCLUDED.date,\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m                sex = EXCLUDED.sex,\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m                location = EXCLUDED.location,\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m                tffrs_meet_id = EXCLUDED.tffrs_meet_id;\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, (race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeet_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mrace\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_url\u001b[39m\u001b[38;5;124m'\u001b[39m], race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m], race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m], race[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtffrs_meet_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     15\u001b[0m         conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'event'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
